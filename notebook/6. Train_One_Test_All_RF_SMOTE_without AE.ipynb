{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"20250519\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11893,
     "status": "ok",
     "timestamp": 1681959704949,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "dXrYwtbeJfQg",
    "outputId": "ae3e21e0-e6c5-45a9-913f-d78180d087c2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    " \n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt \n",
    "# import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D,Input\n",
    "from tensorflow.keras.layers import MaxPooling1D,UpSampling1D,Lambda,Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.losses import mse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# for now()\n",
    "import datetime\n",
    "# for timezone()\n",
    "import pytz\n",
    "# using now() to get current time\n",
    "current_time = datetime.datetime.now(pytz.timezone('America/New_York'))\n",
    "# printing current time in india\n",
    "print(\"The current time is :\", current_time)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681959734637,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "4Yc4eJxSkZuL"
   },
   "outputs": [],
   "source": [
    "# _celline = ['A549','GM12878','H1.hESC','HeLa.S3','HepG2','HT1080','HUVEC','IMR.90','K562','MCF.7','NCI.H460','NHEK','SK.MEL.5','SK.N.DZ','SK.N.SH']\n",
    "_celline = ['A549','GM12878','HeLa.S3']\n",
    "\n",
    "K = 6\n",
    "miss = [2]\n",
    "\n",
    "threshold = \"0\"\n",
    "\n",
    "\n",
    "# # input path\n",
    "path_input = \"../data/mer%s/\"%(K)\n",
    "# output path\n",
    "path_output = \"../results/Train_one_test_all/mer%s_%s/\"%(K,date)\n",
    "\n",
    "path_models = path_output+\"models/\"\n",
    "\n",
    "os.makedirs(path_output, exist_ok=True)\n",
    "os.makedirs(path_models,exist_ok=True)\n",
    "\n",
    "\n",
    "CV = 5\n",
    "max_len = 5000\n",
    "segment = [(200,5000)]\n",
    "\n",
    "_model_type = [\"RF\"]\n",
    "encoding = \"rawcounts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHPDw0KZJfQj"
   },
   "source": [
    "# <font color=blue> Load data</font>\n",
    "##  <font color=blue> load cell_line, kmer counts table, generate two class training set, mean as threshold. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681959734638,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "2h5uamJtJfQn"
   },
   "outputs": [],
   "source": [
    "def assign_class(row, Celline):\n",
    "    if row[Celline] < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def processdata(df):\n",
    "    x_train_ = df.iloc[:,0:-5]\n",
    "    y_train_ = df.iloc[:,-1]\n",
    "    train_rci_ = df.iloc[:,-5:]\n",
    "    \n",
    "    return x_train_,y_train_,train_rci_\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "def evaluate_matrix(cm):\n",
    "    idx = [0,1]\n",
    "    columns = ['Sn','Sp','Preci','MCC','F1-score','OA']\n",
    "    eva = pd.DataFrame(index=idx,columns=columns)\n",
    "    \n",
    "    oa = np.diag(cm).sum()/cm.sum()*100\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        fp = cm.sum(axis=0)[i]-cm[i][i] # sum of column\n",
    "        fn = cm.sum(axis=1)[i]-cm[i][i] # sum of row\n",
    "        tp = cm[i][i]\n",
    "        tn = cm.sum()-(fp+fn+tp)\n",
    "        if tp == 0:\n",
    "            sensitivity = 0\n",
    "            precision = 0\n",
    "        else:\n",
    "            sensitivity = tp / (tp+fn)\n",
    "            precision = tp / (tp+fp)\n",
    "            \n",
    "        specificity = tn / (tn+fp)\n",
    "               \n",
    "        if precision*sensitivity==0:\n",
    "            f1_score=0\n",
    "        else:\n",
    "            f1_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "        if tp*tn-fp*fn == 0:\n",
    "            mcc = 0\n",
    "        else:\n",
    "            mcc = (tp*tn-fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "        if i==0:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,oa]\n",
    "        else:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,0]\n",
    "    \n",
    "    return oa , eva\n",
    "\n",
    "def evaluateModel(model_types,model,x_val,y_val,dff_val):\n",
    "    if model_types == \"RF\":\n",
    "        y_pred_prob = model.predict_proba(x_val)[:, 1] \n",
    "    else:\n",
    "        y_pred_prob = model.predict(x_val).ravel() \n",
    "    auc = roc_auc_score(y_val, y_pred_prob)\n",
    "    \n",
    "    y_pred = (model.predict(x_val) > 0.5).astype(\"int32\")    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    oa, eva = evaluate_matrix(cm)\n",
    "    eva.loc[0,\"AUC\"] = auc\n",
    "    dff_val = pd.concat([dff_val,pd.DataFrame(y_pred,columns=[\"pred\"]),pd.DataFrame(y_pred_prob,columns=[\"prob\"])],axis=1)\n",
    "    \n",
    "\n",
    "    return oa, cm, eva,dff_val,auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681959734639,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "Cmtqq4rZqU12"
   },
   "outputs": [],
   "source": [
    "def train_model(Cell_train):\n",
    "    \n",
    "    # COUNT Running time\n",
    "    start = time.time()\n",
    "\n",
    "    \n",
    "    for j in range(0,2):\n",
    "    \n",
    "        # training dataset split by genes, 5-fold CV\n",
    "        kf = KFold(n_splits=CV,random_state=(j+1)*42, shuffle=True)\n",
    "        i=0\n",
    "        for train_index, val_index in kf.split(genes):\n",
    "            i += 1\n",
    "            print(\"No.{} fold\".format(j*5+i))      \n",
    "\n",
    "            for (m,n) in segment:\n",
    "                # print()\n",
    "                # print(\"Training on {}~{}\".format(m,n))\n",
    "\n",
    "                train_genes = genes.iloc[train_index].gene_id\n",
    "                val_genes = genes.iloc[val_index].gene_id\n",
    "                df_train = _df_train.copy()   ## here\n",
    "#                 df_test = _df_test.copy()\n",
    "\n",
    "                train = df_train.iloc[train_index]\n",
    "                train = train.reset_index(drop=True)                \n",
    "                x_train,y_train,train_rci = processdata(train)                \n",
    "\n",
    "                count = Counter(y_train)\n",
    "                ratio = count[0]/count[1]\n",
    "                print(\"class 0 : class 1 = %.3f.\"%(ratio))\n",
    "                smt = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "                x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "                print(\"After over-sampling\",(Counter(y_train)))          \n",
    "                \n",
    "\n",
    "                val = df_train.iloc[val_index].reset_index(drop=True)\n",
    "                x_val,y_val,val_rci = processdata(val)\n",
    "                \n",
    "                x_train = x_train.to_numpy()\n",
    "                x_val = x_val.to_numpy()\n",
    "\n",
    "                for model_type in _model_type:\n",
    "                    test_set_type = \"lncATLAS\"\n",
    "\n",
    "                    print()\n",
    "                    ### load model\n",
    "                    print(\"\\nTraining on %s %smer%smismatch %s %s %s %s. \\n\"%(Cell_train,K,Q,encoding, model_type,m,n))\n",
    "                    print()\n",
    "                    if model_type == \"1DCNN\":\n",
    "                        k = x_train_ae.shape[1] \n",
    "                        model = build_CNN(x_train_ae.shape[1])            \n",
    "                        x_train_cnn = x_train_ae.reshape(len(x_train_ae),k,1)\n",
    "                        x_val0_cnn = x_val_ae.reshape(len(x_val_ae),k,1)\n",
    "\n",
    "                        model,score = trainModel(ae,j*5+i,m,n,model,Cell_train,model_type,x_train_cnn,x_val0_cnn,y_train_cnn, y_val_cnn)\n",
    "\n",
    "                        val0_eva,val0_len_acc,val0_report,val0_predit = evaluateModel(Cell_train,test_set_type,model_type,model,x_val0_cnn,y_val_cnn,val0_rci)\n",
    "\n",
    "                        \n",
    "                    elif model_type == \"MLP\":\n",
    "                        model = build_MLP(x_train_ae.shape[1])\n",
    "                        model,score = trainModel(ae,j*5+i,m,n,model,Cell_train,model_type,x_train_ae,x_val_ae,y_train_cnn, y_val_cnn)\n",
    "\n",
    "                        val0_eva,val0_len_acc,val0_report,val0_predit = evaluateModel(Cell_train,test_set_type,model_type,model,x_val_ae,y_val_cnn,val0_rci)\n",
    "                        # val_std_eva,val_std_len_acc,val_std_report,val_std_predict = evaluateModel(model,x_val_std,y_val_std,valstd_rci)\n",
    "\n",
    "                        # test_std_eva,test_std_len_acc,test_std_report,test_std_predict = evaluateModel(model,x_test_std,y_test_std,teststd_rci)\n",
    "\n",
    "                    elif model_type == \"RF\":\n",
    "                        model = RandomForestClassifier(n_estimators=100)\n",
    "                        model.fit(x_train,y_train)\n",
    "                        joblib.dump(model,path_models+'/%s_%s_%s_%s_%s_%smer%smiss_fold%s.pkl'%(encoding,Cell_train,model_type,m,n,K,Q,j*5+i))\n",
    "                        y_predit0 = model.predict(x_val)\n",
    "                        score = accuracy_score(y_val,y_predit0)\n",
    "                        print(\"RF accuracy:\",score)\n",
    "                        print()\n",
    "                        oa_val, cm_val, eva_val, val0_predict,auc_val = evaluateModel(model_type, model,x_val,y_val,val_rci)\n",
    "                    \n",
    "                    print(f'model {model_type} val accu {oa_val:.3f}, auc {auc_val:.3f}\\nval cm {cm_val}')\n",
    "                    eva_val0_file =path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Cell_train,Cell_train,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_val = path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_val.xlsx\"%(Cell_train,Cell_train,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "                    writer_eva_val = ExcelWriter(eva_val0_file, engine='openpyxl',mode='a')\n",
    "                    writer_predict_val = ExcelWriter(predict_file_val, engine='openpyxl',mode='a')\n",
    "\n",
    "                    conf_matrix_df = pd.DataFrame(cm_val, columns=['Pred_0', 'Pred_1'], index=['True_0', 'True_1'])    \n",
    "                    eva_val.to_excel(writer_eva_val,sheet_name=\"eva{}\".format(j*5+i))\n",
    "                    conf_matrix_df.to_excel(writer_eva_val,sheet_name=\"CM{}\".format(j*5+i))                    \n",
    "                    val0_predict.to_excel(writer_predict_val,sheet_name=\"predict_0_{}\".format(j*5+i))\n",
    "                    writer_eva_val.close()\n",
    "                    writer_predict_val.close()                                        \n",
    "                    \n",
    "                    for Cell_test in _celline:\n",
    "                        \n",
    "\n",
    "                        print(\"\\nfold %s, train %s, test %s\"%(j*5+i,Cell_train,Cell_test))\n",
    "                        _df_test = data_test.copy()                        \n",
    "                        _df_test[Cell_test] = _test[Cell_test]                        \n",
    "                        _df_test = _df_test.dropna(axis=0).reset_index(drop=True)\n",
    "                        _df_test[\"Class\"] = _df_test.apply(lambda row:assign_class(row,Cell_test),axis=1)\n",
    "\n",
    "                        x_test,y_test,test_rci = processdata(_df_test)\n",
    "                        x_test = x_test.to_numpy()\n",
    "                        oa_test, cm_test,eva_test,test0_predict,auc_test = evaluateModel(model_type,model,x_test,y_test,test_rci)\n",
    "                        print(f'model {model_type} test accu {oa_test:.3f}, auc {auc_test:.3f}\\ntest cm {cm_test}') \n",
    "                        \n",
    "\n",
    "                        eva_test0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                        predict_file_test = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_test.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "                        writer_eva_test = ExcelWriter(eva_test0_file, engine='openpyxl',mode='a')\n",
    "                        writer_predict_test = ExcelWriter(predict_file_test, engine='openpyxl',mode='a') \n",
    "\n",
    "                        conf_matrix_df = pd.DataFrame(cm_test, columns=['Pred_0', 'Pred_1'], index=['True_0', 'True_1'])\n",
    "                        eva_test.to_excel(writer_eva_test,sheet_name=\"eva{}\".format(j*5+i))\n",
    "                        conf_matrix_df.to_excel(writer_eva_test,sheet_name=\"CM{}\".format(j*5+i))\n",
    "                        test0_predict.to_excel(writer_predict_test,sheet_name=\"predict_0_{}\".format(j*5+i))                  \n",
    "\n",
    "                        writer_eva_test.close()\n",
    "                        writer_predict_test.close()\n",
    "                        \n",
    "                        \n",
    "                    del model  # Explicitly delete the model\n",
    "                    gc.collect()  # Run garbage collection\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Running time {} seconds\".format(round(end-start,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPu44te6DWBA"
   },
   "source": [
    "## <font color=\"blue\"> only validation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1UhjWY_RGzRXsCkD2_UVys2yxZ56CTh7D"
    },
    "executionInfo": {
     "elapsed": 1386273,
     "status": "ok",
     "timestamp": 1681971251556,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "pK8ctTWzJfQk",
    "outputId": "23fd0d56-b889-4afc-937e-dfddcda30c15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for Q in miss:\n",
    "    _train = pd.read_csv(path_input+encoding+\"_noncoding_train_%smer%smiss.csv\"%(K,Q),index_col=0)\n",
    "    data_train = _train.iloc[:,0:-18].div(_train.iloc[:,0:-18].sum(axis=1), axis=0)\n",
    "    data_train[[\"transcript_id\",\"gene_id\",\"length\"]] = _train[[\"transcript_id\",\"gene_id\",\"length\"]]\n",
    "\n",
    "    _test = pd.read_csv(path_input+encoding+\"_noncoding_test_%smer%smiss.csv\"%(K,Q),index_col=0)\n",
    "    data_test = _test.iloc[:,0:-18].div(_test.iloc[:,0:-18].sum(axis=1), axis=0)\n",
    "    data_test[[\"transcript_id\",\"gene_id\",\"length\"]] = _test[[\"transcript_id\",\"gene_id\",\"length\"]]\n",
    "\n",
    "\n",
    "    #Create output files\n",
    "    wb = openpyxl.Workbook()\n",
    "\n",
    "    for Cell_train in _celline:\n",
    "        for Cell_test in _celline:\n",
    "            for model_type in _model_type:\n",
    "                for (m,n) in segment:\n",
    "                    \n",
    "                    eva_val0_file = path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_val = path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_val.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    eva_test0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_test = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_test.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    wb.save(eva_val0_file)                                         \n",
    "                    wb.save(predict_file_val)\n",
    "                    wb.save(eva_test0_file)\n",
    "                    wb.save(predict_file_test)\n",
    "\n",
    "    for Cell_train in _celline:\n",
    "        _df_train = data_train.copy()\n",
    "        _df_train[Cell_train] = _train[Cell_train]\n",
    "        _df_train = _df_train.dropna(axis=0)\n",
    "        _df_train = _df_train.sort_values(by=\"length\",ascending=False).reset_index(drop=True)\n",
    "        _df_train[\"Class\"] = _df_train.apply(lambda row:assign_class(row,Cell_train),axis=1)\n",
    "\n",
    "\n",
    "        genes = pd.DataFrame(_df_train.gene_id.unique(),columns=[\"gene_id\"])\n",
    "\n",
    "        print()\n",
    "        print(\"\\n training on %s %smer%smismatch .\"%(Cell_train,K,Q ))\n",
    "\n",
    "        train_model(Cell_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ydcZv53Ifu6",
    "outputId": "48d0dd6d-e5fb-449f-aec4-316638e258df"
   },
   "outputs": [],
   "source": [
    "for Q in miss:\n",
    "    for model_type in _model_type:\n",
    "        for (m,n) in segment:\n",
    "            for Cell_train in _celline:\n",
    "                for Cell_test in _celline:\n",
    "                    \n",
    "                    eva_val0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    eva_test0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    for infile in [eva_test0_file]:\n",
    "                        print(infile)\n",
    "                        writer = ExcelWriter(infile, engine='openpyxl',mode='a',if_sheet_exists='replace')\n",
    "                        xl = pd.ExcelFile(infile)\n",
    "                        eva = []\n",
    "\n",
    "                        for i in range(1,11):\n",
    "                            eva.append(xl.parse('eva'+str(i),index_col=0))\n",
    "\n",
    "                        df_eva_avg =  pd.concat(eva).groupby(level=0).mean()\n",
    "\n",
    "                        df_eva_avg.to_excel(writer,sheet_name='eva_avg')\n",
    "\n",
    "                        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEFWHJ5hL-h-"
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now(pytz.timezone('America/New_York'))\n",
    "# printing current time in india\n",
    "print(\"The current time is :\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kxfbrJkjzC6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "provenance": [
    {
     "file_id": "1p8LBV2HW8bIfdwB6uB3rvn9SBbG4MjdD",
     "timestamp": 1671460227027
    },
    {
     "file_id": "1CGT89_L-rRNCLu5zKdxBj9Iaeo2Ss8UU",
     "timestamp": 1670778999794
    },
    {
     "file_id": "1Ek2f9VMzD343HoqwMLQq0202uDIjfJcy",
     "timestamp": 1670739042300
    },
    {
     "file_id": "1SDHVHJb1iEgBdrg6PIHyFLI1scm1PuLJ",
     "timestamp": 1670732162092
    },
    {
     "file_id": "1oV5sEG_1EnKG3tFKaP2CTb0SY2107AcZ",
     "timestamp": 1670652213334
    },
    {
     "file_id": "1ii8Rdl7iDnH-cw3hn87LL8P8dP5Q9yz5",
     "timestamp": 1670650834800
    },
    {
     "file_id": "1Xz0CVYnlSY_TjDQG5dMplT9hXVS6rJOh",
     "timestamp": 1667429080441
    },
    {
     "file_id": "1IGF8yBSDTAH0V1im7m-pi4fbYMiBDkKp",
     "timestamp": 1667364410817
    },
    {
     "file_id": "1D00xQ1mFTsbdtwFPolX0eZBkfo6V-HNc",
     "timestamp": 1667357423139
    },
    {
     "file_id": "1luTFVLZ4EieGL05DhF3-_VaZPQdY6kkD",
     "timestamp": 1667327677379
    },
    {
     "file_id": "115giBVwy4f8w7HsxYAtGMWmIO0twTMCw",
     "timestamp": 1666885155990
    },
    {
     "file_id": "120BCzNctDT9Yk8zGHVXknFJqTH-3IyGT",
     "timestamp": 1666720696785
    },
    {
     "file_id": "1d--uJIDVQvi3sroek831V_mli8p4ahW_",
     "timestamp": 1666715223346
    },
    {
     "file_id": "1bLzXpwQXJ1zJ2DtTH_iuTm_4Dp4Nc2sC",
     "timestamp": 1666713348905
    },
    {
     "file_id": "1WRuoMqHRooBo_T0rC6PYRAAGMdJBMh1K",
     "timestamp": 1666711895541
    },
    {
     "file_id": "1vfQru6ef0muP1hOTemHvGxwK0IOo-97u",
     "timestamp": 1666711154545
    }
   ],
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

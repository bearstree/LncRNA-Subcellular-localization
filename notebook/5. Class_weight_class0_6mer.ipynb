{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"20250519\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXrYwtbeJfQg",
    "outputId": "848a98be-97c2-4d17-c7b2-74f94d0d0555"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D,Input\n",
    "from tensorflow.keras.layers import MaxPooling1D,UpSampling1D,Lambda,Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# from tensorflow.keras.losses import mse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# for now()\n",
    "import datetime\n",
    "# for timezone()\n",
    "import pytz\n",
    "# using now() to get current time\n",
    "current_time = datetime.datetime.now(pytz.timezone('America/New_York'))\n",
    "# printing current time in india\n",
    "print(\"The current time is :\", current_time)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "Random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Yc4eJxSkZuL"
   },
   "outputs": [],
   "source": [
    "_celline = [\"A549\",\"HT1080\",\"NCI.H460\",\"SK.N.SH\"]\n",
    "\n",
    "threshold = \"threshold_0\"\n",
    "\n",
    "K = 6\n",
    "max_miss = 3\n",
    "\n",
    "process_type = \"normal\"\n",
    "neuron1 = 128\n",
    "neuron2 = 256\n",
    "neuron3 = 256\n",
    "dropout = 0.5\n",
    "\n",
    "folder = f'{neuron1}_{neuron2}_{neuron3}_leakyrelu'\n",
    "\n",
    "# # input path\n",
    "path_input = \"../data/mer%s/\"%(K)\n",
    "# output path\n",
    "path_output = \"../results/Class_weight/mer%s_%s/\"%(K,date)\n",
    "\n",
    "path_models = path_output+\"models/\"\n",
    "\n",
    "os.makedirs(path_output, exist_ok=True)\n",
    "os.makedirs(path_models,exist_ok=True)\n",
    "\n",
    "CV = 5\n",
    "# alpha = -0.25\n",
    "max_len = 5000\n",
    "segment = [(200,5000)]\n",
    "\n",
    "_model_type = [\"1DCNN\",\"MLP\",\"RF\"]\n",
    "\n",
    "encoding = \"rawcounts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHPDw0KZJfQj"
   },
   "source": [
    "# <font color=blue> Load data</font>\n",
    "##  <font color=blue> load cell_line, kmer counts table, generate two class training set, mean as threshold. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNNqaFHZrFD6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "def evaluate_matrix(cm):\n",
    "    idx = [0,1]\n",
    "    columns = ['Sn','Sp','Preci','MCC','F1-score','OA']\n",
    "    eva = pd.DataFrame(index=idx,columns=columns)\n",
    "\n",
    "    oa = np.diag(cm).sum()/cm.sum()*100\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        fp = cm.sum(axis=0)[i]-cm[i][i] # sum of column\n",
    "        fn = cm.sum(axis=1)[i]-cm[i][i] # sum of row\n",
    "        tp = cm[i][i]\n",
    "        tn = cm.sum()-(fp+fn+tp)\n",
    "        if tp == 0:\n",
    "            sensitivity = 0\n",
    "            precision = 0\n",
    "        else:\n",
    "            sensitivity = tp / (tp+fn)\n",
    "            precision = tp / (tp+fp)\n",
    "\n",
    "        specificity = tn / (tn+fp)\n",
    "\n",
    "        if precision*sensitivity==0:\n",
    "            f1_score=0\n",
    "        else:\n",
    "            f1_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "        if tp*tn-fp*fn == 0:\n",
    "            mcc = 0\n",
    "        else:\n",
    "            mcc = (tp*tn-fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "        if i==0:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,oa]\n",
    "        else:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,0]\n",
    "\n",
    "    return oa , eva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2h5uamJtJfQn"
   },
   "outputs": [],
   "source": [
    "def assign_class(row, Celline):\n",
    "    if row[Celline] < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def processdata(dff):\n",
    "    x_train = dff.iloc[:,0:-5]\n",
    "    y_train = dff.iloc[:,-1]\n",
    "    train_rci_ = dff.iloc[:,-5:]\n",
    "    return x_train,y_train,train_rci_\n",
    "\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "def evaluate_matrix(cm):\n",
    "    idx = [0,1]\n",
    "    columns = ['Sn','Sp','Preci','MCC','F1-score','OA']\n",
    "    eva = pd.DataFrame(index=idx,columns=columns)\n",
    "\n",
    "    oa = np.diag(cm).sum()/cm.sum()*100\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        fp = cm.sum(axis=0)[i]-cm[i][i] # sum of column\n",
    "        fn = cm.sum(axis=1)[i]-cm[i][i] # sum of row\n",
    "        tp = cm[i][i]\n",
    "        tn = cm.sum()-(fp+fn+tp)\n",
    "        if tp == 0:\n",
    "            sensitivity = 0\n",
    "            precision = 0\n",
    "        else:\n",
    "            sensitivity = tp / (tp+fn)\n",
    "            precision = tp / (tp+fp)\n",
    "\n",
    "        specificity = tn / (tn+fp)\n",
    "\n",
    "        if precision*sensitivity==0:\n",
    "            f1_score=0\n",
    "        else:\n",
    "            f1_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "        if tp*tn-fp*fn == 0:\n",
    "            mcc = 0\n",
    "        else:\n",
    "            mcc = (tp*tn-fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "        if i==0:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,oa]\n",
    "        else:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,0]\n",
    "\n",
    "    return oa , eva\n",
    "\n",
    "def build_MLP(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(neuron1, input_shape=(input_shape,)),\n",
    "        LeakyReLU(alpha=0.01),\n",
    "        Dropout(0.2),  # Dropout to avoid overfitting\n",
    "        Dense(neuron1//2),\n",
    "        LeakyReLU(alpha=0.01),\n",
    "        Dropout(0.2),\n",
    "        Dense(neuron1//4),\n",
    "        LeakyReLU(alpha=0.01),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
    "    ])\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "#     model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_CNN(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=neuron1, kernel_size=3,kernel_initializer=HeNormal(), input_shape=(input_shape, 1)),\n",
    "        LeakyReLU(alpha=0.01),\n",
    "        MaxPooling1D(pool_size=3),\n",
    "        Conv1D(filters=neuron2, kernel_size=3,kernel_initializer=HeNormal()),\n",
    "        LeakyReLU(alpha=0.01),\n",
    "        MaxPooling1D(pool_size=3),\n",
    "        Flatten(),\n",
    "        Dense(neuron3, kernel_initializer=HeNormal()),\n",
    "        LeakyReLU(alpha=0.01),\n",
    "        Dropout(dropout),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     cnn1.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "############################################################################################################\n",
    "def trainModel(class_weights,n_fold,m,n,model,celline,model_types,x_train,x_val,y_train, y_val):\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode=\"min\",patience=10,verbose=0)\n",
    "    model_checkpoint = ModelCheckpoint(path_models+'%s_%s_%s_%s_%s_%smer%smiss_fold%s.h5'%(encoding,Celline,model_types,m,n,K,Q,n_fold), monitor='val_loss',\n",
    "                                       patience=5, verbose=0, save_best_only=True,save_weights_only=True)\n",
    "\n",
    "    # fit the keras model on the dataset\n",
    "    history = model.fit(x_train, y_train, epochs=30,\n",
    "                        batch_size=32,\n",
    "                        verbose=0,\n",
    "                        callbacks=[early_stopping,model_checkpoint],\n",
    "                        validation_data=(x_val, y_val),class_weight=class_weights)\n",
    "    # evaluate the keras model\n",
    "    model.load_weights(path_models+'%s_%s_%s_%s_%s_%smer%smiss_fold%s.h5'%(encoding,Celline,model_types,m,n,K,Q,n_fold))\n",
    "    score = model.evaluate(x_val, y_val)\n",
    "#     print(\"val accuracy: \",score[1]*100)\n",
    "\n",
    "    return model,score[1]\n",
    "\n",
    "def evaluateModel(model_types,model,x_val,y_val,dff_val):\n",
    "    if model_types == \"RF\":\n",
    "        y_pred_prob = model.predict_proba(x_val)[:, 1] \n",
    "    else:\n",
    "        y_pred_prob = model.predict(x_val).ravel() \n",
    "    auc = roc_auc_score(y_val, y_pred_prob)\n",
    "    \n",
    "    y_pred = (model.predict(x_val) > 0.5).astype(\"int32\")    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    oa, eva = evaluate_matrix(cm)\n",
    "    eva.loc[0,\"AUC\"] = auc\n",
    "    dff_val = pd.concat([dff_val,pd.DataFrame(y_pred,columns=[\"pred\"])],axis=1)\n",
    "\n",
    "    return oa, cm, eva,dff_val,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmtqq4rZqU12"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # COUNT Running time\n",
    "    start = time.time()\n",
    "\n",
    "    #Create output files\n",
    "    wb = openpyxl.Workbook()\n",
    "\n",
    "    for model_type in _model_type:\n",
    "\n",
    "        for (m,n) in segment:\n",
    "        \n",
    "\n",
    "            eva_val0_file = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "            predict_file_val = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_val.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "            eva_test0_file = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "            predict_file_test = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_test.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "#             eva_test_apex_file = path_apex + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test_apex.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "#             predict_file_apex = path_apex + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_apex.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "            wb.save(eva_val0_file)\n",
    "            wb.save(predict_file_val)\n",
    "            wb.save(eva_test0_file)\n",
    "            wb.save(predict_file_test)\n",
    "#             wb.save(eva_test_apex_file)\n",
    "#             wb.save(predict_file_apex)\n",
    "\n",
    "    for j in range(0,2):\n",
    "\n",
    "        # training dataset split by genes, 5-fold CV\n",
    "        kf = KFold(n_splits=CV,random_state=(j+1)*42, shuffle=True)\n",
    "        i=0\n",
    "        for train_index, val_index in kf.split(genes):\n",
    "            i += 1\n",
    "            print(\"{} No.{} fold\".format(Celline,j*5+i))\n",
    "\n",
    "            for (m,n) in segment:\n",
    "                df_train = _df_train.copy()   ## here\n",
    "                df_test = _df_test.copy()\n",
    "#                 df_apex = _df_apex.copy()\n",
    "\n",
    "                train = df_train.iloc[train_index]\n",
    "                train = train.reset_index(drop=True)                \n",
    "                x_train,y_train,train_rci = processdata(train)                \n",
    "#                 x_train = x_train.div(train_rci[\"length\"]-K+1,axis=0)\n",
    "             \n",
    "                class_weights = class_weight.compute_class_weight(class_weight='balanced', \n",
    "                                                  classes=np.unique(y_train), \n",
    "                                                  y=y_train)\n",
    "                class_weights = dict(enumerate(class_weights))\n",
    "                \n",
    "                count = Counter(y_train)\n",
    "                ratio = count[0]/count[1]\n",
    "                print(\"class 0 : class 1 = %.3f.\"%(ratio))\n",
    "\n",
    "                val = df_train.iloc[val_index].reset_index(drop=True)\n",
    "                x_val,y_val,val_rci = processdata(val)\n",
    "\n",
    "\n",
    "                test = df_test.copy()\n",
    "                x_test,y_test,test_rci = processdata(test)\n",
    "\n",
    "                x_train = x_train.to_numpy()\n",
    "                x_val = x_val.to_numpy()\n",
    "                x_test = x_test.to_numpy()\n",
    "\n",
    "                input_dim = x_train.shape[1]\n",
    "\n",
    "                for model_type in _model_type:\n",
    "                    print()\n",
    "                    ### load model\n",
    "                    print(\"Training on  %s %smer%smismatch %s %s %s %s. \"%(Celline,K,Q,encoding, model_type,m,n))\n",
    "                    print()\n",
    "                    if model_type == \"1DCNN\":\n",
    "                        k = x_train.shape[1]\n",
    "                        model = build_CNN(x_train.shape[1])\n",
    "                        x_train_cnn = x_train.reshape(len(x_train),k,1)\n",
    "                        x_val0_cnn = x_val.reshape(len(x_val),k,1)\n",
    "                        x_test0_cnn = x_test.reshape(len(x_test),k,1)\n",
    "#                         x_test_apex_cnn = x_test_apex.reshape(len(x_test_apex),k,1)\n",
    "\n",
    "                        model,score = trainModel(class_weights,j*5+i,m,n,model,Celline,model_type,x_train_cnn,x_val0_cnn,y_train, y_val)\n",
    "\n",
    "                        oa_val, cm_val, eva_val, val0_predict,auc_val = evaluateModel(model_type,model,x_val0_cnn,y_val,val_rci)\n",
    "                        oa_test, cm_test,eva_test,test0_predict,auc_test = evaluateModel(model_type,model,x_test0_cnn,y_test,test_rci)\n",
    "#                         test_apex_eva,test_apex_len_acc,test_apex_report,test_apex_predict = evaluateModel(\"apex\",model_type,model,x_test_apex_cnn,y_test_apex_cnn,apex_pre)\n",
    "                        tf.keras.backend.clear_session()\n",
    "                        gc.collect()\n",
    "\n",
    "                    elif model_type == \"MLP\":\n",
    "                        model = build_MLP(x_train.shape[1])\n",
    "                        model,score = trainModel(class_weights, j*5+i,m,n,model,Celline,model_type,x_train,x_val,y_train, y_val)\n",
    "                        oa_val, cm_val, eva_val, val0_predict,auc_val = evaluateModel(model_type,model,x_val,y_val,val_rci)\n",
    "                        oa_test, cm_test,eva_test,test0_predict,auc_test = evaluateModel(model_type,model,x_test,y_test,test_rci)\n",
    "#                         test_apex_eva,test_apex_len_acc,test_apex_report,test_apex_predict = evaluateModel(\"apex\",model_type,model,x_test_apex,y_test_apex_cnn,apex_pre)\n",
    "                        tf.keras.backend.clear_session()\n",
    "                        gc.collect()\n",
    "        \n",
    "                    else:\n",
    "                        model_type == \"RF\"\n",
    "                        model = RandomForestClassifier(n_estimators=200,class_weight=class_weights,random_state=42,n_jobs=-1)\n",
    "                        model.fit(x_train,y_train)\n",
    "                        joblib.dump(model,path_models+'%s_%s_%s_%s_%s_%smer%smiss_fold%s.h5'%(encoding,Celline,model_type,m,n,K,Q,j*5+i))\n",
    "                        y_predit0 = model.predict(x_val)\n",
    "                        score = accuracy_score(y_val,y_predit0)\n",
    "                        print(\"RF accuracy:\",score)\n",
    "                        print()\n",
    "                        oa_val, cm_val, eva_val, val0_predict,auc_val = evaluateModel(model_type,model,x_val,y_val,val_rci)\n",
    "                        oa_test, cm_test,eva_test,test0_predict,auc_test = evaluateModel(model_type,model,x_test,y_test,test_rci)\n",
    "#                         test_apex_eva,test_apex_len_acc,test_apex_report,test_apex_predict = evaluateModel(\"apex\",model_type,model,x_test_apex,y_test_apex,apex_pre)\n",
    "                        del model  # Explicitly delete the model\n",
    "                        gc.collect()  # Run garbage collection\n",
    "\n",
    "                    ## validation class threshold 0 and mean+/-std\n",
    "                    print(f'model {model_type} val accu {oa_val:.3f}, auc {auc_val:.3f}\\nval cm {cm_val}')\n",
    "                    print(f'model {model_type} test accu {oa_test:.3f}, auc {auc_test:.3f}\\ntest cm {cm_test}')\n",
    "            \n",
    "                    eva_val0_file = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_val = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_val.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "                    writer_eva_val0 = ExcelWriter(eva_val0_file, engine='openpyxl',mode='a')\n",
    "                    # writer_eva_valstd = ExcelWriter(eva_valstd_file, engine='openpyxl',mode='a')\n",
    "                    writer_predict_val = ExcelWriter(predict_file_val, engine='openpyxl',mode='a')\n",
    "                    \n",
    "                    conf_matrix_df = pd.DataFrame(cm_val, columns=['Pred_0', 'Pred_1'], index=['True_0', 'True_1'])    \n",
    "\n",
    "                    eva_val.to_excel(writer_eva_val0,sheet_name=\"eva{}\".format(j*5+i))\n",
    "                    conf_matrix_df.to_excel(writer_eva_val0,sheet_name=\"CM{}\".format(j*5+i))                    \n",
    "                    val0_predict.to_excel(writer_predict_val,sheet_name=\"predict_0_{}\".format(j*5+i))\n",
    "\n",
    "                    writer_eva_val0.close()\n",
    "                    # writer_eva_valstd.close()\n",
    "                    writer_predict_val.close()\n",
    "\n",
    "\n",
    "                    ## prediction on test,threshold 0 and mean+/-std\n",
    "\n",
    "\n",
    "                    eva_test0_file = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_test = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_test.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "                    writer_eva_test0 = ExcelWriter(eva_test0_file, engine='openpyxl',mode='a')\n",
    "                    writer_predict_test = ExcelWriter(predict_file_test, engine='openpyxl',mode='a')\n",
    "                    \n",
    "                    conf_matrix_df = pd.DataFrame(cm_test, columns=['Pred_0', 'Pred_1'], index=['True_0', 'True_1'])  \n",
    "\n",
    "                    eva_test.to_excel(writer_eva_test0,sheet_name=\"eva{}\".format(j*5+i))\n",
    "                    conf_matrix_df.to_excel(writer_eva_test0,sheet_name=\"CM{}\".format(j*5+i))\n",
    "                    test0_predict.to_excel(writer_predict_test,sheet_name=\"predict_0_{}\".format(j*5+i))                  \n",
    "\n",
    "                    writer_eva_test0.close()\n",
    "                    writer_predict_test.close()\n",
    "\n",
    "\n",
    "#                     eva_test_apex_file = path_apex + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test_apex.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "#                     predict_file_apex = path_apex + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_apex.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "#                     writer_eva_test_apex = ExcelWriter(eva_test_apex_file, engine='openpyxl',mode='a')\n",
    "#                     writer_predict_test_apex = ExcelWriter(predict_file_apex, engine='openpyxl',mode='a')\n",
    "\n",
    "#                     test_apex_eva.to_excel(writer_eva_test_apex,sheet_name=\"eva{}\".format(j*5+i))\n",
    "#                     test_apex_len_acc.to_excel(writer_eva_test_apex,sheet_name=\"len_acc{}\".format(j*5+i))\n",
    "#                     test_apex_report.to_excel(writer_eva_test_apex,sheet_name=\"report{}\".format(j*5+i))\n",
    "#                     test_apex_predict.to_excel(writer_predict_test_apex,sheet_name=\"predict_0_{}\".format(j*5+i))  \n",
    "\n",
    "#                     writer_eva_test_apex.close()\n",
    "#                     writer_predict_test_apex.close()\n",
    "                        \n",
    "                        \n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Running time {} seconds\".format(round(end-start,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPu44te6DWBA"
   },
   "source": [
    "## <font color=\"blue\"> only validation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pK8ctTWzJfQk",
    "outputId": "b1d1010c-b492-4fe5-fb12-9b2d94a992e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for Q in range(0,max_miss+1):\n",
    "    _train = pd.read_csv(path_input+encoding+\"_noncoding_train_%smer%smiss.csv\"%(K,Q),index_col=0)\n",
    "    data_train = _train.iloc[:,0:-18].div(_train.iloc[:,0:-18].sum(axis=1), axis=0)\n",
    "    data_train[[\"transcript_id\",\"gene_id\",\"length\"]] = _train[[\"transcript_id\",\"gene_id\",\"length\"]]\n",
    "\n",
    "    _test = pd.read_csv(path_input+encoding+\"_noncoding_test_%smer%smiss.csv\"%(K,Q),index_col=0)\n",
    "    data_test = _test.iloc[:,0:-18].div(_test.iloc[:,0:-18].sum(axis=1), axis=0)\n",
    "    data_test[[\"transcript_id\",\"gene_id\",\"length\"]] = _test[[\"transcript_id\",\"gene_id\",\"length\"]]\n",
    "\n",
    "#     _apex = pd.read_csv(apex_seq+encoding+\"_coding_apex_%smer%smiss_200-5000_longest.csv\"%(K,Q),index_col=0)\n",
    "#     data_apex = _apex.iloc[:,0:-6].div(_apex[\"length\"],axis=0)\n",
    "#     data_apex[[\"transcript_id\",\"gene_id\",\"length\",\"Class\"]] =  _apex[[\"transcript_id\",\"gene_id\",\"length\",\"Class\"]]\n",
    "\n",
    "\n",
    "    for Celline in _celline:\n",
    "        _df_train = data_train.copy()\n",
    "        _df_train[Celline] = _train[Celline]\n",
    "        _df_train = _df_train.dropna(axis=0)\n",
    "        _df_train = _df_train.sort_values(by=\"length\",ascending=False).reset_index(drop=True)\n",
    "        _df_train[\"Class\"] = _df_train.apply(lambda row:assign_class(row,Celline),axis=1)\n",
    "\n",
    "        _df_test = data_test.copy()\n",
    "        _df_test[Celline] = _test[Celline]\n",
    "        _df_test = _df_test.dropna(axis=0).reset_index(drop=True)\n",
    "        _df_test[\"Class\"] = _df_test.apply(lambda row:assign_class(row,Celline),axis=1)\n",
    "\n",
    "#         _df_apex = data_apex.copy()\n",
    "#         _df_apex[\"Class\"] = _apex[\"Class\"]\n",
    "#         _df_apex = _df_apex.dropna(axis=0).reset_index(drop=True)\n",
    "\n",
    "        genes = pd.DataFrame(_df_train.gene_id.unique(),columns=[\"gene_id\"])\n",
    "\n",
    "        print()\n",
    "        print(\"training on %s %smer%smismatch .\"%(Celline,K,Q ))\n",
    "        \n",
    "\n",
    "        train()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ydcZv53Ifu6",
    "outputId": "76cece1f-590d-408e-f676-5f382037ef40"
   },
   "outputs": [],
   "source": [
    "_celline = [\"A549\"]\n",
    "for model_type in _model_type:\n",
    "    for (m,n) in segment:\n",
    "        for Celline in _celline:\n",
    "            for Q in range(0,max_miss+1):\n",
    "                \n",
    "                eva_val0_file = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "                eva_test0_file = path_output + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "#                 eva_test_apex_file = path_apex + \"10fold_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test_apex.xlsx\"%(Celline,m,n,encoding,threshold,model_type,K,Q)\n",
    "                for infile in [eva_val0_file,eva_test0_file]:\n",
    "                    print(infile)\n",
    "                    writer = ExcelWriter(infile, engine='openpyxl',mode='a')\n",
    "                    xl = pd.ExcelFile(infile)\n",
    "                    eva = []\n",
    "                    \n",
    "                    for i in range(1,11):\n",
    "                        eva.append(xl.parse('eva'+str(i),index_col=0))\n",
    "                        \n",
    "                    df_eva_avg =  pd.concat(eva).groupby(level=0).mean()\n",
    "\n",
    "                    df_eva_avg.to_excel(writer,sheet_name='eva_avg')\n",
    "                   \n",
    "                    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEFWHJ5hL-h-",
    "outputId": "b59e1713-7fbc-4a50-82e2-6dac10187637"
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now(pytz.timezone('America/New_York'))\n",
    "# printing current time in india\n",
    "print(\"The current time is :\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kxfbrJkjzC6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"20250519\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11893,
     "status": "ok",
     "timestamp": 1681959704949,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "dXrYwtbeJfQg",
    "outputId": "ae3e21e0-e6c5-45a9-913f-d78180d087c2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt \n",
    "# import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D,Input, Conv1DTranspose, Concatenate\n",
    "from tensorflow.keras.layers import MaxPooling1D,UpSampling1D,Lambda,Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "\n",
    "from tensorflow.keras.losses import mse,binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as BK\n",
    "\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# for now()\n",
    "import datetime\n",
    "# for timezone()\n",
    "import pytz\n",
    "# using now() to get current time\n",
    "current_time = datetime.datetime.now(pytz.timezone('America/New_York'))\n",
    "# printing current time in india\n",
    "print(\"The current time is :\", current_time)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681959734637,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "4Yc4eJxSkZuL"
   },
   "outputs": [],
   "source": [
    "# _celline = ['A549','GM12878','H1.hESC','HeLa.S3','HepG2','HT1080','HUVEC','IMR.90','K562','MCF.7','NCI.H460','NHEK','SK.MEL.5','SK.N.DZ','SK.N.SH']\n",
    "_celline = ['IMR.90','K562','HepG2']\n",
    "K = 6\n",
    "miss = [2]\n",
    "\n",
    "threshold = \"0\"\n",
    "\n",
    "encoding_dim = 512\n",
    "\n",
    "# # input path\n",
    "path_input = \"../data/mer%s/\"%(K)\n",
    "# output path\n",
    "path_output = \"../results/Train_one_test_all/with_AE/mer%s_%s/\"%(K,date)\n",
    "\n",
    "path_models = path_output+\"models/\"\n",
    "ae_path = path_output + \"ae_models/\"\n",
    "\n",
    "os.makedirs(path_output, exist_ok=True)\n",
    "os.makedirs(path_models,exist_ok=True)\n",
    "os.makedirs(ae_path, exist_ok=True)\n",
    "\n",
    "CV = 5\n",
    "max_len = 5000\n",
    "segment = [(200,5000)]\n",
    "\n",
    "_model_type = [\"1DCNN\"]\n",
    "ae_type = [\"AE_MLP\"]\n",
    "\n",
    "encoding = \"rawcounts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHPDw0KZJfQj"
   },
   "source": [
    "# <font color=blue> Load data</font>\n",
    "##  <font color=blue> load cell_line, kmer counts table, generate two class training set, mean as threshold. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681959734638,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "2h5uamJtJfQn"
   },
   "outputs": [],
   "source": [
    "def assign_class(row, Celline):\n",
    "    if row[Celline] < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def processdata(df):\n",
    "    x_train_ = df.iloc[:,0:-5]\n",
    "    y_train_ = df.iloc[:,-1]\n",
    "    train_rci_ = df.iloc[:,-5:]\n",
    "    \n",
    "    return x_train_,y_train_,train_rci_\n",
    "\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "def evaluate_matrix(cm):\n",
    "    idx = [0,1]\n",
    "    columns = ['Sn','Sp','Preci','MCC','F1-score','OA']\n",
    "    eva = pd.DataFrame(index=idx,columns=columns)\n",
    "    \n",
    "    oa = np.diag(cm).sum()/cm.sum()*100\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        fp = cm.sum(axis=0)[i]-cm[i][i] # sum of column\n",
    "        fn = cm.sum(axis=1)[i]-cm[i][i] # sum of row\n",
    "        tp = cm[i][i]\n",
    "        tn = cm.sum()-(fp+fn+tp)\n",
    "        if tp == 0:\n",
    "            sensitivity = 0\n",
    "            precision = 0\n",
    "        else:\n",
    "            sensitivity = tp / (tp+fn)\n",
    "            precision = tp / (tp+fp)\n",
    "            \n",
    "        specificity = tn / (tn+fp)\n",
    "               \n",
    "        if precision*sensitivity==0:\n",
    "            f1_score=0\n",
    "        else:\n",
    "            f1_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "        if tp*tn-fp*fn == 0:\n",
    "            mcc = 0\n",
    "        else:\n",
    "            mcc = (tp*tn-fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "        if i==0:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,oa]\n",
    "        else:\n",
    "            eva.loc[i] = [sensitivity,specificity,precision,mcc,f1_score,0]\n",
    "    \n",
    "    return oa , eva\n",
    "\n",
    "def build_CNN(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu', kernel_initializer=HeNormal(), input_shape=(input_shape, 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        Conv1D(filters=256, kernel_size=3, activation='relu', kernel_initializer=HeNormal()),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu', kernel_initializer=HeNormal()),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     cnn1.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def trainModel(ae_type,n_fold,m,n,model,celline,model_types,x_train,x_val,y_train, y_val):\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode=\"min\",patience=10,verbose=0)\n",
    "    model_checkpoint = ModelCheckpoint(path_models+'%s_%s_%s_%s_%s_%smer%smiss_%s_fold%s.h5'%(encoding,celline,model_types,m,n,K,Q,ae_type,n_fold), monitor='val_loss',\n",
    "                                       mode='min', verbose=0, save_best_only=True,save_weights_only=True)\n",
    "\n",
    "    # fit the keras model on the dataset\n",
    "    history = model.fit(x_train, y_train, epochs=30,\n",
    "                        batch_size=128,\n",
    "                        verbose=0,\n",
    "                        callbacks=[early_stopping,model_checkpoint],\n",
    "                        validation_data=(x_val, y_val))\n",
    "    # evaluate the keras model\n",
    "    model.load_weights(path_models+'%s_%s_%s_%s_%s_%smer%smiss_%s_fold%s.h5'%(encoding,celline,model_types,m,n,K,Q,ae_type,n_fold))\n",
    "    score = model.evaluate(x_val, y_val)\n",
    "    print(\"val accuracy: \",score[1]*100)\n",
    "\n",
    "    return model,score[1]\n",
    "\n",
    "def evaluateModel(model_types,model,x_val,y_val,dff_val):\n",
    "    if model_types == \"RF\":\n",
    "        y_pred_prob = model.predict_proba(x_val)[:, 1] \n",
    "    else:\n",
    "        y_pred_prob = model.predict(x_val).ravel() \n",
    "#     print(f'predict prob: {y_pred_prob}')\n",
    "    auc = roc_auc_score(y_val, y_pred_prob)\n",
    "    \n",
    "    y_pred = (model.predict(x_val) > 0.5).astype(\"int32\")    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    oa, eva = evaluate_matrix(cm)\n",
    "    eva.loc[0,\"AUC\"] = auc\n",
    "    dff_val = pd.concat([dff_val,pd.DataFrame(y_pred,columns=[\"pred\"]),pd.DataFrame(y_pred_prob,columns=[\"prob\"])],axis=1)\n",
    "\n",
    "    return oa, cm, eva,dff_val,auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681959734638,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "qRD2873NlX5l"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "def AE_mlp(x_train_,x_val_,input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    # Encoder\n",
    "    encoded = Dense(256, activation='relu')(input_layer)\n",
    "    encoded = BatchNormalization()(encoded)\n",
    "    encoded = Dense(128, activation='relu')(encoded)\n",
    "    encoded = BatchNormalization()(encoded)\n",
    "    encoded = Dropout(0.3)(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Dense(128, activation='relu')(encoded)\n",
    "    decoded = Dense(256, activation='relu')(decoded)\n",
    "    decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
    "    # define autoencoder model\n",
    "    ae_mlp = Model(input_layer, decoded)\n",
    "    # compile autoencoder model\n",
    "    \n",
    "    ae_mlp.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    ae_mlp.summary()\n",
    "\n",
    "#     checkpointer = ModelCheckpoint(filepath=path1+'bestmodel.h5', verbose=0, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n",
    "\n",
    "    #v fit the autoencoder model to reconstruct input\n",
    "    history = ae_mlp.fit(x_train_, x_train_,\n",
    "                        epochs=200, batch_size=128, verbose=0,\n",
    "                        callbacks=[earlystopper],\n",
    "                        validation_data=(x_val_,x_val_))\n",
    "    \n",
    "    encoder_mlp = Model(input_layer,encoded, name='ae_mlp')\n",
    "    # plot loss\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return encoder_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681959734639,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "Cmtqq4rZqU12"
   },
   "outputs": [],
   "source": [
    "def train_model(Cell_train):\n",
    "    \n",
    "    # COUNT Running time\n",
    "    start = time.time()\n",
    "\n",
    "    for j in range(0,2):\n",
    "   \n",
    "        # training dataset split by genes, 5-fold CV\n",
    "        kf = KFold(n_splits=CV,random_state=(j+1)*42, shuffle=True)\n",
    "        i=0\n",
    "        Score = {\"1DCNN\":0,\"MLP\":0} \n",
    "        for train_index, val_index in kf.split(genes):\n",
    "            i += 1\n",
    "            print(\"No.{} fold\".format(j*5+i))      \n",
    "            for (m,n) in segment:\n",
    "\n",
    "                df_train = _df_train.copy()   ## here\n",
    "\n",
    "                train = df_train.iloc[train_index]\n",
    "                train = train.reset_index(drop=True)                \n",
    "                x_train,y_train,train_rci = processdata(train)               \n",
    "            \n",
    "                count = Counter(y_train)\n",
    "                ratio = count[0]/count[1]\n",
    "                print(\"class 0 : class 1 = %.3f.\"%(ratio))\n",
    "\n",
    "                val = df_train.iloc[val_index].reset_index(drop=True)\n",
    "                x_val,y_val,val_rci = processdata(val)\n",
    "    \n",
    "                x_train = x_train.to_numpy()\n",
    "                x_val = x_val.to_numpy()\n",
    "  \n",
    "                input_dim = x_train.shape[1]\n",
    "\n",
    "                for ae in ae_type:\n",
    "                    smt = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "                    if ae == \"AE_MLP\":\n",
    "                        enc_mlp = AE_mlp(x_train,x_val,input_dim)\n",
    "                        enc_mlp.save(ae_path+\"%s_Celline_%s_fea%s_latent%s_%smer%smiss_fold%s.h5\"%(ae,Cell_train,input_dim,encoding_dim,K,Q,j*5+i))\n",
    "#                         enc_mlp = load_model(ae_path+\"%s_Celline_%s_fea%s_latent%s_%smer%smiss_fold%s.h5\"%(ae,Celline,input_dim,encoding_dim,K,Q,j*5+i),compile=False)\n",
    "                        x_train_ae = enc_mlp.predict(x_train)\n",
    "                        x_train_ae, y_train_ae = smt.fit_resample(x_train_ae, y_train)\n",
    "                        print(\"%s After over-sampling %s\"%(ae,Counter(y_train_ae)))\n",
    "                        x_val_ae = enc_mlp.predict(x_val)\n",
    "\n",
    "                    for model_type in _model_type:\n",
    "                        print()\n",
    "                        ### load model\n",
    "                        print(\"\\nTraining on %s %smer%smismatch %s,%s %s %s %s. \"%(Cell_train,K,Q,ae,encoding, model_type,m,n))\n",
    "                        print()\n",
    "                        if model_type == \"1DCNN\":\n",
    "                            k = x_train_ae.shape[1]\n",
    "                            model = build_CNN(x_train_ae.shape[1])\n",
    "                            x_train_cnn = x_train_ae.reshape(len(x_train_ae),k,1)\n",
    "                            x_val_cnn = x_val_ae.reshape(len(x_val_ae),k,1)\n",
    "                            model,score = trainModel(ae,j*5+i,m,n,model,Cell_train,model_type,x_train_cnn,x_val_cnn,y_train_ae, y_val)\n",
    "                            oa_val, cm_val, eva_val, val0_predict,auc_val = evaluateModel(model_type,model,x_val_cnn,y_val,val_rci)\n",
    "                        print(f'model {model_type} val accu {oa_val:.3f}, auc {auc_val:.3f}\\nval cm {cm_val}')\n",
    "                        eva_val0_file =path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Cell_train,Cell_train,m,n,encoding,threshold,model_type,K,Q)\n",
    "                        predict_file_val = path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_val.xlsx\"%(Cell_train,Cell_train,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "                        writer_eva_val = ExcelWriter(eva_val0_file, engine='openpyxl',mode='a')\n",
    "                        writer_predict_val = ExcelWriter(predict_file_val, engine='openpyxl',mode='a')\n",
    "\n",
    "                        conf_matrix_df = pd.DataFrame(cm_val, columns=['Pred_0', 'Pred_1'], index=['True_0', 'True_1'])    \n",
    "                        eva_val.to_excel(writer_eva_val,sheet_name=\"eva{}\".format(j*5+i))\n",
    "                        conf_matrix_df.to_excel(writer_eva_val,sheet_name=\"CM{}\".format(j*5+i))                    \n",
    "                        val0_predict.to_excel(writer_predict_val,sheet_name=\"predict_0_{}\".format(j*5+i))\n",
    "                        writer_eva_val.close()\n",
    "                        writer_predict_val.close()      \n",
    "\n",
    "                        \n",
    "                        for Cell_test in _celline:\n",
    "                           \n",
    "                            print(\"\\nfold %s, train %s, test %s\"%(j*5+i,Cell_train,Cell_test))\n",
    "                            _df_test = data_test.copy()\n",
    "                            _df_test[Cell_test] = _test[Cell_test]\n",
    "                            _df_test = _df_test.dropna(axis=0).reset_index(drop=True)\n",
    "                            _df_test[\"Class\"] = _df_test.apply(lambda row:assign_class(row,Cell_test),axis=1)\n",
    "\n",
    "                            x_test,y_test,test_rci = processdata(_df_test)\n",
    "                            x_test = x_test.to_numpy()\n",
    "                            x_test_ae = enc_mlp.predict(x_test)\n",
    "                            x_test = x_test_ae.reshape(len(x_test_ae),k,1)\n",
    "                            oa_test, cm_test,eva_test,test0_predict,auc_test = evaluateModel(model_type,model,x_test,y_test,test_rci)\n",
    "                            print(f'model {model_type} test accu {oa_test:.3f}, auc {auc_test:.3f}\\ntest cm {cm_test}')    \n",
    "\n",
    "                            ## prediction on test,threshold 0 and mean+/-std\n",
    "\n",
    "\n",
    "                            eva_test0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                            predict_file_test = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_test.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "\n",
    "                            writer_eva_test = ExcelWriter(eva_test0_file, engine='openpyxl',mode='a')\n",
    "                            writer_predict_test = ExcelWriter(predict_file_test, engine='openpyxl',mode='a') \n",
    "\n",
    "                            conf_matrix_df = pd.DataFrame(cm_test, columns=['Pred_0', 'Pred_1'], index=['True_0', 'True_1'])\n",
    "                            eva_test.to_excel(writer_eva_test,sheet_name=\"eva{}\".format(j*5+i))\n",
    "                            conf_matrix_df.to_excel(writer_eva_test,sheet_name=\"CM{}\".format(j*5+i))\n",
    "                            test0_predict.to_excel(writer_predict_test,sheet_name=\"predict_0_{}\".format(j*5+i))                  \n",
    "\n",
    "                            writer_eva_test.close()\n",
    "                            writer_predict_test.close()\n",
    "\n",
    "                        tf.keras.backend.clear_session()\n",
    "                        gc.collect()\n",
    "    end = time.time()\n",
    "    print(\"Running time {} seconds\".format(round(end-start,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPu44te6DWBA"
   },
   "source": [
    "## <font color=\"blue\"> only validation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1UhjWY_RGzRXsCkD2_UVys2yxZ56CTh7D"
    },
    "executionInfo": {
     "elapsed": 1386273,
     "status": "ok",
     "timestamp": 1681971251556,
     "user": {
      "displayName": "Weijun Yi",
      "userId": "09680254186711267766"
     },
     "user_tz": 240
    },
    "id": "pK8ctTWzJfQk",
    "outputId": "23fd0d56-b889-4afc-937e-dfddcda30c15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for Q in miss:\n",
    "    _train = pd.read_csv(path_input+encoding+\"_noncoding_train_%smer%smiss.csv\"%(K,Q),index_col=0)\n",
    "    data_train = _train.iloc[:,0:-18].div(_train.iloc[:,0:-18].sum(axis=1), axis=0)\n",
    "    data_train[[\"transcript_id\",\"gene_id\",\"length\"]] = _train[[\"transcript_id\",\"gene_id\",\"length\"]]\n",
    "\n",
    "    _test = pd.read_csv(path_input+encoding+\"_noncoding_test_%smer%smiss.csv\"%(K,Q),index_col=0)\n",
    "    data_test = _test.iloc[:,0:-18].div(_test.iloc[:,0:-18].sum(axis=1), axis=0)\n",
    "    data_test[[\"transcript_id\",\"gene_id\",\"length\"]] = _test[[\"transcript_id\",\"gene_id\",\"length\"]]\n",
    "\n",
    "\n",
    "\n",
    "    #Create output files\n",
    "    wb = openpyxl.Workbook()\n",
    "\n",
    "    for Cell_train in _celline:\n",
    "\n",
    "        for Cell_test in _celline:\n",
    "            for model_type in _model_type:\n",
    "\n",
    "                for (m,n) in segment:\n",
    "                    \n",
    "                    eva_val0_file = path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_val = path_output + \"10fold_train_%s_val_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_val.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    eva_test0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    predict_file_test = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_predict_test.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                    wb.save(eva_val0_file)                                         \n",
    "                    wb.save(predict_file_val)\n",
    "                    wb.save(eva_test0_file)\n",
    "                    wb.save(predict_file_test)\n",
    "\n",
    "    ## Whole training mean and std as test threshold\n",
    "    for Cell_train in _celline:\n",
    "        _df_train = data_train.copy()\n",
    "        _df_train[Cell_train] = _train[Cell_train]\n",
    "        _df_train = _df_train.dropna(axis=0)\n",
    "        _df_train = _df_train.sort_values(by=\"length\",ascending=False).reset_index(drop=True)\n",
    "        _df_train[\"Class\"] = _df_train.apply(lambda row:assign_class(row,Cell_train),axis=1)\n",
    "\n",
    "\n",
    "        genes = pd.DataFrame(_df_train.gene_id.unique(),columns=[\"gene_id\"])\n",
    "\n",
    "        print()\n",
    "        print(\"\\n training on %s %smer%smismatch .\"%(Cell_train,K,Q ))\n",
    "\n",
    "        train_model(Cell_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ydcZv53Ifu6",
    "outputId": "48d0dd6d-e5fb-449f-aec4-316638e258df"
   },
   "outputs": [],
   "source": [
    "for Q in miss:\n",
    "    for model_type in _model_type:\n",
    "        for (m,n) in segment:\n",
    "            for Cell_train in _celline:\n",
    "                for Cell_test in _celline:\n",
    "                    for ae in ae_type:\n",
    "#                         eva_val0_file = path1 + \"10fold_train_%s_test_%s_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_val0.xlsx\"%(Cell_train,Cell_test,ae,m,n,encoding,threshold,model_type,K,Q)\n",
    "                        eva_test0_file = path_output + \"10fold_train_%s_test_%s_training_length_%s_%s_%s_%s_%s_%smer%smiss_test0.xlsx\"%(Cell_train,Cell_test,m,n,encoding,threshold,model_type,K,Q)\n",
    "                        for infile in [eva_test0_file]:\n",
    "                            print(infile)\n",
    "                            writer = ExcelWriter(infile, engine='openpyxl',mode='a',if_sheet_exists='replace')\n",
    "                            xl = pd.ExcelFile(infile)\n",
    "                            eva = []\n",
    "\n",
    "                            for i in range(1,11):\n",
    "                                eva.append(xl.parse('eva'+str(i),index_col=0))\n",
    "\n",
    "                            df_eva_avg =  pd.concat(eva).groupby(level=0).mean()\n",
    "\n",
    "                            df_eva_avg.to_excel(writer,sheet_name='eva_avg')\n",
    "\n",
    "                            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEFWHJ5hL-h-"
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now(pytz.timezone('America/New_York'))\n",
    "# printing current time in india\n",
    "print(\"The current time is :\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kxfbrJkjzC6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "provenance": [
    {
     "file_id": "1p8LBV2HW8bIfdwB6uB3rvn9SBbG4MjdD",
     "timestamp": 1671460227027
    },
    {
     "file_id": "1CGT89_L-rRNCLu5zKdxBj9Iaeo2Ss8UU",
     "timestamp": 1670778999794
    },
    {
     "file_id": "1Ek2f9VMzD343HoqwMLQq0202uDIjfJcy",
     "timestamp": 1670739042300
    },
    {
     "file_id": "1SDHVHJb1iEgBdrg6PIHyFLI1scm1PuLJ",
     "timestamp": 1670732162092
    },
    {
     "file_id": "1oV5sEG_1EnKG3tFKaP2CTb0SY2107AcZ",
     "timestamp": 1670652213334
    },
    {
     "file_id": "1ii8Rdl7iDnH-cw3hn87LL8P8dP5Q9yz5",
     "timestamp": 1670650834800
    },
    {
     "file_id": "1Xz0CVYnlSY_TjDQG5dMplT9hXVS6rJOh",
     "timestamp": 1667429080441
    },
    {
     "file_id": "1IGF8yBSDTAH0V1im7m-pi4fbYMiBDkKp",
     "timestamp": 1667364410817
    },
    {
     "file_id": "1D00xQ1mFTsbdtwFPolX0eZBkfo6V-HNc",
     "timestamp": 1667357423139
    },
    {
     "file_id": "1luTFVLZ4EieGL05DhF3-_VaZPQdY6kkD",
     "timestamp": 1667327677379
    },
    {
     "file_id": "115giBVwy4f8w7HsxYAtGMWmIO0twTMCw",
     "timestamp": 1666885155990
    },
    {
     "file_id": "120BCzNctDT9Yk8zGHVXknFJqTH-3IyGT",
     "timestamp": 1666720696785
    },
    {
     "file_id": "1d--uJIDVQvi3sroek831V_mli8p4ahW_",
     "timestamp": 1666715223346
    },
    {
     "file_id": "1bLzXpwQXJ1zJ2DtTH_iuTm_4Dp4Nc2sC",
     "timestamp": 1666713348905
    },
    {
     "file_id": "1WRuoMqHRooBo_T0rC6PYRAAGMdJBMh1K",
     "timestamp": 1666711895541
    },
    {
     "file_id": "1vfQru6ef0muP1hOTemHvGxwK0IOo-97u",
     "timestamp": 1666711154545
    }
   ],
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
